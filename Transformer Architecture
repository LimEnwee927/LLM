{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43511421-4c15-4341-a207-cc7d80ec3bd7",
   "metadata": {},
   "source": [
    "# Creating Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dacd754-7604-4496-b0ba-182749e37a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Total number of words: 20479\n",
      "I HAD always th\n"
     ]
    }
   ],
   "source": [
    "with open(\"Theverdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total number of words:\", len(raw_text))\n",
    "print(raw_text[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656a837-b748-4b91-a9f6-593e3e7e6dd8",
   "metadata": {},
   "source": [
    "## Split text and obtained list of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "095128b1-f85f-4836-86b9-5baf47a9320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', 'world.', 'This,', 'is', 'a', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r' ', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b2d5ff-ef2b-4bf5-bee3-9262801d7169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', 'world.', 'This,', 'is', 'a', 'test.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cf833bd-afdc-412b-8cef-f726c852fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Lew', 'Jeslynn', 'a', 'real', 'LvBu', 'Dancing', 'with', 'demon']\n"
     ]
    }
   ],
   "source": [
    "Fact = \"Hello, Lew. Jeslynn? a real: LvBu--Dancing with demon?\"\n",
    "\n",
    "splitted = re.split(r'[([,.:;?_!\"()\\']|--|\\s', Fact)\n",
    "splitted = [item for item in splitted\n",
    "            if item.strip()]\n",
    "print(splitted[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdb900fd-bd07-4ebe-9aae-6724a1e153e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n",
      "4690\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[0:30])\n",
    "print(len(preprocessed))\n",
    "\n",
    "#item.strip() will return an empty string if the item is only spaces, \n",
    "#so if item.strip() will exclude empty strings from the final list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050beaca-ce3c-48db-83c0-5e9b0e9dcffe",
   "metadata": {},
   "source": [
    "## Creating Token ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8e425ec-0e30-4974-8420-70a4e91d4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed)) \n",
    "##(set)no words repeated, sort vocab in alphabetical order\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14cb638d-b73f-4c84-a52d-816a4071a8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '!')\n",
      "(1, '\"')\n",
      "(2, \"'\")\n",
      "(3, '(')\n",
      "(4, ')')\n",
      "(5, ',')\n",
      "(6, '--')\n",
      "(7, '.')\n",
      "(8, ':')\n",
      "(9, ';')\n",
      "(10, '?')\n",
      "(11, 'A')\n",
      "(12, 'Ah')\n",
      "(13, 'Among')\n",
      "(14, 'And')\n",
      "(15, 'Are')\n",
      "(16, 'Arrt')\n",
      "(17, 'As')\n",
      "(18, 'At')\n",
      "(19, 'Be')\n",
      "(20, 'Begin')\n",
      "(21, 'Burlington')\n",
      "(22, 'But')\n",
      "(23, 'By')\n",
      "(24, 'Carlo')\n",
      "(25, 'Chicago')\n",
      "(26, 'Claude')\n",
      "(27, 'Come')\n",
      "(28, 'Croft')\n",
      "(29, 'Destroyed')\n",
      "(30, 'Devonshire')\n",
      "(31, 'Don')\n",
      "(32, 'Dubarry')\n",
      "(33, 'Emperors')\n",
      "(34, 'Florence')\n",
      "(35, 'For')\n",
      "(36, 'Gallery')\n",
      "(37, 'Gideon')\n",
      "(38, 'Gisburn')\n",
      "(39, 'Gisburns')\n",
      "(40, 'Grafton')\n",
      "(41, 'Greek')\n",
      "(42, 'Grindle')\n",
      "(43, 'Grindles')\n",
      "(44, 'HAD')\n",
      "(45, 'Had')\n",
      "(46, 'Hang')\n",
      "(47, 'Has')\n",
      "(48, 'He')\n",
      "(49, 'Her')\n"
     ]
    }
   ],
   "source": [
    "vocab = {token: integer for integer,token in enumerate(all_words)}\n",
    "i=0\n",
    "for item in enumerate(vocab):\n",
    "    i = i+1\n",
    "    print(item)\n",
    "    if i>=50:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5325b8e9-33d4-41e2-b466-e6ca317dd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [ item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s  in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join(self.int_to_str[i] for i in ids) #\" \".join--takes the elements of list and seperate it with space\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) ##space + punctuation, r'\\1' means replace space with punctuation(first captured group)\n",
    "        return text\n",
    "        \n",
    "#for s, i in vocab.items():\n",
    "#This part is a for loop that iterates through each tuple in the vocab.items() result.\n",
    "#In each iteration, it unpacks the tuple into two variables:\n",
    "\n",
    "#s will get the key (the word, e.g., \"hello\").\n",
    "#i will get the value (the integer, e.g., 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9c6077a-e58e-4119-bca3-f649830baff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f94e1b46-6fd1-4ce7-acb8-2855c0e1ce1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7815c28-accf-410c-9120-4f6cbf4dd6ca",
   "metadata": {},
   "source": [
    "# Add Special Token to process unknown word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36a4b649-dbdf-4456-84b0-5f598ba831ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))  #set:remove duplicate, sort alphabetical order\n",
    "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a728459-48ec-4601-9fde-5c242e20c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token: integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "faf90016-9ac3-49d5-96aa-8ebf26f6197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! 0\n",
      "\" 1\n",
      "' 2\n",
      "( 3\n",
      ") 4\n",
      ", 5\n",
      "-- 6\n",
      ". 7\n",
      ": 8\n",
      "; 9\n",
      "? 10\n",
      "A 11\n",
      "Ah 12\n",
      "Among 13\n",
      "And 14\n",
      "Are 15\n",
      "Arrt 16\n",
      "As 17\n",
      "At 18\n",
      "Be 19\n",
      "Begin 20\n",
      "Burlington 21\n",
      "But 22\n",
      "By 23\n",
      "Carlo 24\n",
      "Chicago 25\n",
      "Claude 26\n",
      "Come 27\n",
      "Croft 28\n",
      "Destroyed 29\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for token,index in vocab.items():\n",
    "    x=x+1\n",
    "    print(token, index\n",
    "         )\n",
    "    if x>=30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0ca79b4-be14-4ded-92da-9677757cd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "54c89c80-ff4d-488a-a800-2eb30c525334",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \"<|endoftext|>\".join((text1,text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7bbe212-c0cc-4364-9eee-d5c0afe048ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea?<|endoftext|>In the sunlit terraces of the palace.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<|unk|>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdecode(tokenizer\u001b[38;5;241m.\u001b[39mencode(text))\n",
      "Cell \u001b[0;32mIn[83], line 14\u001b[0m, in \u001b[0;36mSimpleTokenizerV2.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      9\u001b[0m     preprocessed \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int  \u001b[38;5;66;03m# Keep the item if it's in the vocabulary\u001b[39;00m\n\u001b[1;32m     10\u001b[0m                     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|unk|>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed]  \u001b[38;5;66;03m# Replace with <|unk|> if not\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convert tokens to ids, using str_to_int and ensuring <|unk|> is handled\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int\u001b[38;5;241m.\u001b[39mget(s, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<|unk|>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     16\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[0;31mKeyError\u001b[0m: '<|unk|>'"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "tokenizer.encode(text)\n",
    "tokenizer.decode(tokenizer.encode(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376d1a1-42b1-43e9-a29a-b26d44de9716",
   "metadata": {},
   "source": [
    "# Byte Pair Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7ff0e41-4026-4651-a4b0-fda24635f79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/limenwee/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/limenwee/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/limenwee/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/limenwee/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/limenwee/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.6/982.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a7c994a-9b35-4c45-937e-5aa605337231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(importlib.metadata.version(\"tiktoken\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9d79b1a-0d8c-4b0d-9c6c-02a1498b91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd54d85-ec62-4bc8-b77e-3170b0704d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "553dea86-7188-4834-90a4-98bc3230fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22290, 37207, 77, 318, 257, 1103, 21551]\n"
     ]
    }
   ],
   "source": [
    "incredible = tokenizer.encode(\"JesLynn is a real bitch\")\n",
    "\n",
    "print(incredible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9743e7da-e270-442e-ae61-09dbb8da9efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JesLynn is a real bitch'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(incredible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77e680ba-818a-4d61-a8ea-c3fad3e54c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"Theverdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e14475-1e9b-4b52-97e0-dadd04603518",
   "metadata": {},
   "source": [
    "# Input-Target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d9aeecb-92d9-4e93-ae6c-b203f475d425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] ----> 367\n",
      "[40, 367] ----> 2885\n",
      "[40, 367, 2885] ----> 1464\n",
      "[40, 367, 2885, 1464] ----> 1807\n"
     ]
    }
   ],
   "source": [
    "enc_sample = enc_text[50:]\n",
    "context_size = 4\n",
    "\n",
    "for i in range(1, context_size+1):\n",
    "    input = enc_text[:i]\n",
    "    desired = enc_text[i]\n",
    "\n",
    "    print(input, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a04b7411-5431-436a-8c13-0f15b817bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---->  H\n",
      "I H ----> AD\n",
      "I HAD ---->  always\n",
      "I HAD always ---->  thought\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    input = enc_text[:i]\n",
    "    desired = enc_text[i]\n",
    "\n",
    "    print(tokenizer.decode(input), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326be795-c961-408f-b944-df3a84d03e87",
   "metadata": {},
   "source": [
    "## Implementing Data Loader (SLiding Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bda11396-ad7b-4e1c-bbf5-5ef67e56deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "\n",
    "    def __init__(self, text, tokenizer, max_lengths, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "   \n",
    "        for i in range(0,len(token_ids)-max_lengths, stride):\n",
    "            input_chunks = token_ids[i : i+ max_lengths]\n",
    "            target_chunks = token_ids[i+1:i+max_lengths+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunks))\n",
    "            self.target_ids.append(torch.tensor(target_chunks))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aebf7f75-d570-46c7-8f13-0da2e5546b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/limenwee/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/limenwee/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/limenwee/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/limenwee/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/limenwee/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/limenwee/lib/python3.12/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/limenwee/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/limenwee/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/limenwee/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/limenwee/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efeb256-606e-4b5a-b2ee-d062707db29d",
   "metadata": {},
   "source": [
    "## Used the Sliding windows above to load inputs in batces using data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71fdc043-5595-42a0-be83-0f09df497d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    #tkenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    #Create Data Set\n",
    "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
    "\n",
    "    #Data loader --batch\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c24b3e70-b269-40a9-80ac-c3cea851e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"Theverdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f40a86a-9265-4edf-89dd-1b1fdad68433",
   "metadata": {},
   "source": [
    "## convert data loader to iterator to enable next function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58e1662f-cdd9-4ae6-9b2f-611b9f0783cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(text, batch_size=8, max_length=4,stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4b427de8-d366-4acb-96bf-ce716496dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[  287,   262,  6001,   286],\n",
      "        [  465, 13476,    11,   339],\n",
      "        [  550,  5710,   465, 12036],\n",
      "        [   11,  6405,   257,  5527],\n",
      "        [27075,    11,   290,  4920],\n",
      "        [ 2241,   287,   257,  4489],\n",
      "        [   64,   319,   262, 34686],\n",
      "        [41976,    13,   357, 10915]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  262,  6001,   286,   465],\n",
      "        [13476,    11,   339,   550],\n",
      "        [ 5710,   465, 12036,    11],\n",
      "        [ 6405,   257,  5527, 27075],\n",
      "        [   11,   290,  4920,  2241],\n",
      "        [  287,   257,  4489,    64],\n",
      "        [  319,   262, 34686, 41976],\n",
      "        [   13,   357, 10915,   314]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba30d4-3397-454a-bf80-5952326d0549",
   "metadata": {},
   "source": [
    "## Creating Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "73db29cb-5533-4e2b-9e6f-480822abc2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c08e0d9b-8d81-4436-97b2-172f4c7ec206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8195,  0.4111,  1.3138],\n",
      "        [-0.8195,  0.4111,  1.3138],\n",
      "        [-0.0888, -0.8039, -0.2451],\n",
      "        [-0.4687,  0.1624, -0.4597]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "output_dim = 3\n",
    "\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)       ## tokens should be [0,vocab_size-1]\n",
    "embeddings = embedding_layer(input_ids)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f667ff4-6649-4859-8605-95f7afb4c854",
   "metadata": {},
   "source": [
    "## Positional EMbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6f623623-f275-4039-9a86-9de84055075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "dimen_size = 256\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ea58d07c-dba4-467d-9a14-f36babb88157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokken_embedding_layer = torch.nn.Embedding(vocab_size, dimen_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a54f262a-7843-40ab-8530-88bde26651f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50257, 256)\n"
     ]
    }
   ],
   "source": [
    "print(tokken_embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1106bf78-79b4-461a-8473-7b058be63eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n"
     ]
    }
   ],
   "source": [
    "##create a dataset for embedding\n",
    "\n",
    "dataloader = create_dataloader_v1(text, batch_size=8, max_length=4,stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "356dcf1c-10dc-4920-975b-23145a2c431c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7159,  0.0146, -0.4537,  ...,  0.7180,  0.9636,  0.2438],\n",
      "         [ 0.8703,  1.2536,  0.7627,  ..., -0.0459,  1.2612, -0.2203],\n",
      "         [ 1.7173,  0.4014,  0.3540,  ...,  0.6634,  0.6097, -0.8871],\n",
      "         [ 0.1395, -0.5534,  2.0400,  ...,  1.4906,  0.2134, -0.5812]],\n",
      "\n",
      "        [[ 1.7515, -1.1877,  0.9934,  ..., -1.1648,  2.0055, -0.6712],\n",
      "         [ 0.6544, -0.4488, -0.1706,  ..., -0.8443, -0.6225, -0.0730],\n",
      "         [-1.8699,  0.8092,  0.1980,  ..., -0.5457, -1.8276, -0.1148],\n",
      "         [ 0.5803,  0.7404,  0.4604,  ...,  1.0429,  1.1408, -1.7025]],\n",
      "\n",
      "        [[ 0.4502, -0.1223,  0.4485,  ..., -0.9984,  1.1200,  0.9636],\n",
      "         [ 0.3136, -0.4262, -1.1028,  ...,  0.2687, -0.9545, -0.2569],\n",
      "         [-0.4658, -0.3848, -0.2368,  ...,  0.0383,  1.1299, -0.3021],\n",
      "         [-0.3433, -1.2831, -0.7804,  ...,  0.2580, -0.4674,  0.6002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4237, -0.4144, -0.9554,  ...,  1.3653,  1.2940, -0.5426],\n",
      "         [ 0.0983, -0.9963, -0.7989,  ..., -0.5254, -0.1576,  1.2371],\n",
      "         [-0.7623,  0.7673,  0.6390,  ...,  1.5848, -0.7161,  1.8432],\n",
      "         [ 1.2738,  0.4079, -0.3002,  ...,  0.3382,  0.4244, -0.1129]],\n",
      "\n",
      "        [[ 1.4064, -1.0266, -1.9213,  ..., -0.5368,  1.0433, -0.7829],\n",
      "         [ 0.9425, -0.1642, -0.1781,  ...,  0.9426, -0.3162,  1.5489],\n",
      "         [-2.5088, -0.2689,  2.1344,  ...,  1.4340,  0.8370,  1.1000],\n",
      "         [-1.5616, -0.6659,  0.5697,  ..., -0.9151,  1.8027, -1.6105]],\n",
      "\n",
      "        [[-2.5088, -0.2689,  2.1344,  ...,  1.4340,  0.8370,  1.1000],\n",
      "         [-1.0025,  0.0068, -1.1848,  ..., -0.3308,  0.3365,  1.1251],\n",
      "         [ 0.5560, -0.1883, -0.7309,  ..., -0.2829,  1.3500, -0.7248],\n",
      "         [ 0.6753, -1.0386,  1.7914,  ...,  0.1466,  0.7009,  0.1606]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#start normal embedding\n",
    "\n",
    "tokken_embeddings = tokken_embedding_layer(inputs)\n",
    "print(tokken_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "30299994-3a6c-4632-9e33-1d51d23e9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding layer is the one who do embedding\n",
    "\n",
    "pos_embedding_layer = torch.nn.Embedding(4, dimen_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8ba875ec-9488-4cd8-b7ce-ea207ef7e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0436,  0.5431,  0.8108,  ..., -0.4953,  0.7169,  0.5584],\n",
      "        [-0.9077, -0.3240, -2.0500,  ...,  0.8433, -0.3229,  0.3830],\n",
      "        [ 0.0392, -1.1928,  0.4372,  ..., -0.8235,  1.5061, -0.1620],\n",
      "        [-0.2034, -0.2812, -1.4937,  ...,  0.6740, -0.1082,  0.3117]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##arrange function: each chunk got 4 tokens, hence, arrange(4) indicates that each chunk\n",
    "##is being labeled as [0,1,2,3]\n",
    "\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(4))\n",
    "print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b717e3-35e3-4b71-a015-8d1711af36aa",
   "metadata": {},
   "source": [
    "## Add positional and normal embeddings together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "178e5c0a-cd3a-4b05-964b-dd65cefc6146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.5950e-01,  5.5771e-01,  3.5701e-01,  ...,  2.2279e-01,\n",
      "           1.6805e+00,  8.0216e-01],\n",
      "         [-3.7321e-02,  9.2962e-01, -1.2873e+00,  ...,  7.9741e-01,\n",
      "           9.3835e-01,  1.6275e-01],\n",
      "         [ 1.7566e+00, -7.9136e-01,  7.9115e-01,  ..., -1.6003e-01,\n",
      "           2.1159e+00, -1.0491e+00],\n",
      "         [-6.3925e-02, -8.3457e-01,  5.4625e-01,  ...,  2.1645e+00,\n",
      "           1.0519e-01, -2.6943e-01]],\n",
      "\n",
      "        [[ 1.7952e+00, -6.4460e-01,  1.8041e+00,  ..., -1.6600e+00,\n",
      "           2.7224e+00, -1.1277e-01],\n",
      "         [-2.5328e-01, -7.7271e-01, -2.2206e+00,  ..., -9.9331e-04,\n",
      "          -9.4542e-01,  3.1007e-01],\n",
      "         [-1.8307e+00, -3.8359e-01,  6.3520e-01,  ..., -1.3692e+00,\n",
      "          -3.2144e-01, -2.7688e-01],\n",
      "         [ 3.7689e-01,  4.5930e-01, -1.0333e+00,  ...,  1.7168e+00,\n",
      "           1.0325e+00, -1.3908e+00]],\n",
      "\n",
      "        [[ 4.9386e-01,  4.2083e-01,  1.2592e+00,  ..., -1.4937e+00,\n",
      "           1.8370e+00,  1.5220e+00],\n",
      "         [-5.9410e-01, -7.5014e-01, -3.1528e+00,  ...,  1.1121e+00,\n",
      "          -1.2773e+00,  1.2613e-01],\n",
      "         [-4.2653e-01, -1.5776e+00,  2.0034e-01,  ..., -7.8512e-01,\n",
      "           2.6360e+00, -4.6417e-01],\n",
      "         [-5.4678e-01, -1.5642e+00, -2.2741e+00,  ...,  9.3194e-01,\n",
      "          -5.7562e-01,  9.1192e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.6734e-01,  1.2871e-01, -1.4468e-01,  ...,  8.7009e-01,\n",
      "           2.0109e+00,  1.5823e-02],\n",
      "         [-8.0941e-01, -1.3203e+00, -2.8489e+00,  ...,  3.1792e-01,\n",
      "          -4.8046e-01,  1.6202e+00],\n",
      "         [-7.2311e-01, -4.2547e-01,  1.0762e+00,  ...,  7.6131e-01,\n",
      "           7.9003e-01,  1.6812e+00],\n",
      "         [ 1.0704e+00,  1.2673e-01, -1.7940e+00,  ...,  1.0121e+00,\n",
      "           3.1620e-01,  1.9884e-01]],\n",
      "\n",
      "        [[ 1.4500e+00, -4.8352e-01, -1.1105e+00,  ..., -1.0321e+00,\n",
      "           1.7602e+00, -2.2447e-01],\n",
      "         [ 3.4852e-02, -4.8813e-01, -2.2281e+00,  ...,  1.7859e+00,\n",
      "          -6.3912e-01,  1.9319e+00],\n",
      "         [-2.4696e+00, -1.4617e+00,  2.5716e+00,  ...,  6.1054e-01,\n",
      "           2.3431e+00,  9.3792e-01],\n",
      "         [-1.7651e+00, -9.4705e-01, -9.2406e-01,  ..., -2.4112e-01,\n",
      "           1.6945e+00, -1.2988e+00]],\n",
      "\n",
      "        [[-2.4652e+00,  2.7424e-01,  2.9452e+00,  ...,  9.3876e-01,\n",
      "           1.5539e+00,  1.6584e+00],\n",
      "         [-1.9102e+00, -3.1711e-01, -3.2348e+00,  ...,  5.1251e-01,\n",
      "           1.3613e-02,  1.5081e+00],\n",
      "         [ 5.9521e-01, -1.3811e+00, -2.9369e-01,  ..., -1.1064e+00,\n",
      "           2.8562e+00, -8.8686e-01],\n",
      "         [ 4.7191e-01, -1.3197e+00,  2.9764e-01,  ...,  8.2059e-01,\n",
      "           5.9263e-01,  4.7237e-01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = tokken_embeddings + pos_embeddings\n",
    "print(input_embeddings)\n",
    "print(input_embeddings.shape)\n",
    "\n",
    "## the dimensiion of both pos and normal embeddings must be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0c3c5-b357-488a-b8c9-1189f98e70a3",
   "metadata": {},
   "source": [
    "## Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6467e111-c127-4ac7-b3dd-2cb1726eed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "query = inputs[1]\n",
    "atten_2 = torch.empty(6)\n",
    "for index, token in enumerate(inputs):\n",
    "     atten_2[index] = torch.dot(token, query)  ##can only use tensor for the second value of dot\n",
    "\n",
    "print(atten_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba82c7e-2667-4c5a-b533-248b0f05beb7",
   "metadata": {},
   "source": [
    "## use soft max to unified the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51a3a6-4984-4de5-aa5b-930a593c5811",
   "metadata": {},
   "source": [
    "## use soft max to unified the value to total = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bae4147-e3b0-4664-acb3-bf134ba843eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights= tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "atten_2 = torch.softmax(atten_2, dim = 0)\n",
    "print(\"Attention weights=\" ,atten_2)\n",
    "print(atten_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb793f-ca89-469f-a598-4beb4764475a",
   "metadata": {},
   "source": [
    "## Context Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076d4ffc-3a10-43ac-a9e1-25fb0bc3d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "context_vector2 = torch.empty(3)\n",
    "\n",
    "for index, tokens in enumerate(inputs):\n",
    "    context_vector2 = context_vector2 + atten_2[index]*tokens\n",
    "\n",
    "print(context_vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d32061-0e37-43af-9143-1c7de0127834",
   "metadata": {},
   "source": [
    "## More efficient way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7bf23c-2e43-42eb-b6eb-4e4f279014fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = inputs @ inputs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65e1c7d-a998-4fa2-af0b-f308454a6bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim = -1)\n",
    "contextvec = attn_weights @ inputs\n",
    "print(contextvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b54ac06-24f7-4af0-9073-1bb396ea41b2",
   "metadata": {},
   "source": [
    "## with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9058c46d-6a01-4fa3-9a32-8206aaf37a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "import torch.nn as nn\n",
    "d_in = 3\n",
    "d_ot = 2\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328a47c2-d9b7-43df-8b10-4d90e5cc6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7fd017-0cd9-475f-9893-a19f7a34e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5337, -0.1051],\n",
      "        [-0.5323, -0.1080],\n",
      "        [-0.5323, -0.1079],\n",
      "        [-0.5297, -0.1076],\n",
      "        [-0.5311, -0.1066],\n",
      "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "sa_v2 = SelfAttention_v2(3, 2)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38cad92-6143-4bdb-9525-981ba9052af8",
   "metadata": {},
   "source": [
    "##casual attention mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12747713-0ded-4370-9112-0c1a0577bc6d",
   "metadata": {},
   "source": [
    "## Masked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eeef201-9d12-4c77-9f62-d668c97b5c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
      "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
      "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)  ##reuse query and keys\n",
    "keys = sa_v2.W_key(inputs)  ##query= one word in sequence, key= all word in sequence\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim =1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47935b04-f9ee-4edb-b44b-588634833764",
   "metadata": {},
   "source": [
    "## Use Trill function to mask value above diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795ff2b-bb98-4cd2-87a0-4d970e74b445",
   "metadata": {},
   "source": [
    "##demo with one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c381e386-8ceb-428d-b453-2ab005346c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = torch.ones(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83ee2dfd-08fc-4028-b213-ebd902315cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "mask_demo = torch.tril(demo)\n",
    "print(mask_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19929127-87c9-47a4-b129-b5ab47a48e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = attn_scores.shape[0]  ##access the size of first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68bfd4ce-5994-4426-8939-47eb503d291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "masked_simple = attn_weights*mask_simple \n",
    "print(masked_simple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa308a9f-f0db-4a8d-b365-4ab23e92b61c",
   "metadata": {},
   "source": [
    "##renormalize the attention weight to sum up 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9477f3b9-6a2a-49c3-8240-37801e129a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_sum = masked_simple.sum(dim = 1, keepdim = True) ## dim = 1 perform sum in each row, keepidm = True keeps the result on the same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46ac5a9a-4f13-4a4e-9832-f640166307f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple_norm = masked_simple/rows_sum\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "956cd48b-baec-4c9a-87d8-fdfaf430aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e152898f-24ed-4cc5-8327-488a275c3650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]],\n",
      "\n",
      "        [[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]]])\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6ae9cf9-3b7a-482d-befb-38a3a37a3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5604e507-8556-4ab5-b10c-9c9aeb9a0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class multiheadwrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList\n",
    "        ([CausalAttention(d_in, d_out, context_length, dropout) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim = -1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c98a801-5418-48c9-a734-4992f55416b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "result = torch.concat((A, B), dim=-1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd380c65-3755-4597-a710-2719541f356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n",
      "tensor([[[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]],\n",
      "\n",
      "        [[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8dcf90-6894-48f5-84b5-84e760cc66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(234)\n",
    "context_length = batch.size\n",
    "d_in = 3\n",
    "d_out = 2\n",
    "num_heads = 2\n",
    "\n",
    "mha = multiheadwrapper(d_in, d_out, context_length,0.0, num_heads)\n",
    "\n",
    "context_vec = mha(batch)\n",
    "print(mha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f8924-9c9a-4864-a0e6-921e4bf48b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b357bb9-2536-4a45-8cd1-10c2251fff92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c658d9d-cd66-4167-bd4d-ac833fd34dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9755b-99d3-444f-be71-516f5d263c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f8caa-e7e9-4fbb-81a6-f3511f5155c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68986eb2-56bc-4856-9ddb-6ba6f7dbe087",
   "metadata": {},
   "source": [
    "# Gelu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3be6647a-7576-4a39-adeb-d6a4448ff8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gelu(nn.Module):\n",
    "     def forward(self, x):\n",
    "        return 0.5*x*(1 + torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi) ) *(x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65814c4-32ab-4d9e-998a-b855fb91d7c1",
   "metadata": {},
   "source": [
    "## Shortcut Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cd45dbc-0e33-49b9-8a33-8cea0669c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),  nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), nn.GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):  ## x is the input tensor\n",
    "        for layer in self.layers:\n",
    "            ## compute the output of current layer\n",
    "            layer_output = layer(x)\n",
    "            ## see whether to implement short cut or not\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "660d4238-7103-4440-8bb0-45dd7d1383ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([1.0, 0.0, -1.0])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = DeepNeuralNetwork(layer_sizes, use_shortcut = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94210882-c93d-47fb-b8c9-f76417076e09",
   "metadata": {},
   "source": [
    "## Coding Attention and FeedForward Layer in Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f2ec6e-1e6a-4dbc-879e-715ea9a3e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d705770-6086-4c69-a211-71508211e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        ##creating learnable parameter, model will adjust scale and shift to minimize loss function\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeroes(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = True)\n",
    "        norm_x = (x-mean)/torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "        \n",
    "class GELU(nn.Module):\n",
    "    def __init_(self):\n",
    "        super().__init__()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1 + torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi) ) *(x + 0.044715 * torch.pow(x, 3))))\n",
    "        \n",
    "class FeedForward(nn.Module):   ## expand GELU and contract\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]), ##expand\n",
    "            GELU(), ##Acctivation\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"]) ## contract\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878faf58-af06-4306-9256-ae4bec09e2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
